{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H5 to MDA Converter for Mountainsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Takes in data that has already been preprocessed in h5_explorer (or h5_subtractor if subtracting probe data)\n",
    "- Original paper was Chung et al. 2017 in Neuron. That version of mountainsort is already obsolete.\n",
    "- Latest MS is here: https://github.com/flatironinstitute/mountainsort_examples/blob/master/docs/preparing_datasets.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"experiment_C20200330-175336_filtered_64.h5\"\n",
    "fs = 3000\n",
    "chan_range = [0,64] # starting at channel 0, not channel 1\n",
    "row_num = [21,20,21] # rows per column (# values should == # columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "from mlpy import mdaio\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the Multichannel Data\n",
    "- Data has been pre-processed and already reflect the 0.195 datapoint/microvolt conversion from the willow system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 1800000 rows and 64 columns.\n"
     ]
    }
   ],
   "source": [
    "f_data = h5py.File(datafile, 'r')\n",
    "xs = f_data.get('sample_index') # channel # (x)\n",
    "ys = f_data.get('channel_data') # actual data in microvolts (y)\n",
    "print (\"Data has \" + str(ys.shape[0]) + \" rows and \" + str(ys.shape[1]) + \" columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an M x N array\n",
    "- M = # channels (rows)\n",
    "- N = # timepoints (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed data has 64 rows and 1800000 columns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data will need to be transposed for mountainsort\n",
    "mn = np.transpose(ys)\n",
    "print (\"Transposed data has \" + str(mn.shape[0]) + \" rows and \" + str(mn.shape[1]) + \" columns.\")\n",
    "\n",
    "# 32bit save function\n",
    "mdaio.writemda32(ys[0:4, 60000:75000],'raw.mda')\n",
    "\n",
    "#print(ys[0:30000, 0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a probe map (1 shank)\n",
    "- based off of probe maps designed in the original paper(Chung et al 2017 PMID: 28910621)\n",
    "- As of April 2020 that version of MS is already obsolete, so map design may need to change for future versions\n",
    "- Additional documentation from the latest version (in dev) is here https://github.com/flatironinstitute/mountainsort_examples/blob/master/docs/preparing_datasets.md\n",
    "- #### Note that the mountainsort probe map is different than for kilosort\n",
    "- #### Waiting on the final probe map from Jorg, so this is a best guess at the arrangement. Ch 42 (#41 in python notation) should be a dead channel (reserved for the wiring)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arry = np.empty(shape = [ys.shape[1],2])\n",
    "j = 0 # probe column #\n",
    "row_val = -321\n",
    "for chan in range(0, ys.shape[1]):\n",
    "    if j == 0:\n",
    "        arry[chan][0] = 0\n",
    "        row_val = row_val + 15\n",
    "        arry[chan][1] = row_val\n",
    "    elif j == 1:\n",
    "        arry[chan][0] = 22\n",
    "        arry[chan][1] = row_val\n",
    "    elif j == 2:\n",
    "        arry[chan][0] = 44\n",
    "        arry[chan][1] = row_val\n",
    "        j = -1\n",
    "    \n",
    "    j = j + 1   \n",
    "\n",
    "geom = pd.DataFrame(arry)\n",
    "display(HTML(geom.to_html()))\n",
    "geom.to_csv('geom.csv', index = False)\n",
    "#f_shank1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lead_conda",
   "language": "python",
   "name": "leaf_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
