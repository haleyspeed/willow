{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick and choose functions as needed\n",
    "- Reads in an h5 file from Lead Labs Willow System\n",
    "- Scaling function to turn raw data into microvolts\n",
    "- Filtering routine between user specified cutoffs (butterworth bandpass)\n",
    "- Downsampling routine to 1kHz for oscillatory activity\n",
    "- Displays raw traces from each channel as they are arranged on the probe shank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz, filtfilt\n",
    "import time\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input File (Required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definition: Import a single h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_h5 (datafile, chan_start, chan_end, time_start, time_end, fs):\n",
    "    channels = list(np.arange(chan_start, chan_end)) # list of channels for the current shank\n",
    "    f_data = h5py.File(datafile, 'r') # Read in the h5 file\n",
    "    x_values = f_data.get('sample_index') # time in datapoints (x)\n",
    "    y_values = f_data.get('channel_data')  # actual data in raw format, must be scaled to microvolts (y)\n",
    "    \n",
    "    # keep only the time window and channels that we specified in user input\n",
    "    x_values = x_values[time_start*fs:time_end*fs] \n",
    "    y_values = y_values[time_start*fs:time_end*fs, channels]\n",
    "    f_data.close()\n",
    "    display (HTML(\"Data consists of \" + str(y_values.shape[1]) + \n",
    "              \" columns of data (channels, x) and \" + str(y_values.shape[0]) + \n",
    "              \" rows of data (measurements, y).\" + \"The recording is \" +\n",
    "              str(round(ys.shape[0]/(fs * 60),3)) + \" mins long.\"))\n",
    "    display (HTML(\"x-axis data (in datapoints) is stored in the <strong>x_values</strong> variable. <br>\"))\n",
    "    display (HTML(\"y-axis data is stored in the <strong>y_values</strong> variable. <br>\"))\n",
    "    return x_values, y_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: Import a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'experiment_C20200330-174152_concat.h5' \n",
    "fs = 30000 # sample rate\n",
    "window = [0, 30] # time window of analysis (for filtering, 4 mins max for most computers)\n",
    "chan_num = [0,128] # channels on the shank\n",
    "\n",
    "# Call the get_single_h5() function\n",
    "x_values, y_values = get_single_h5 (datafile, chan_num[0], chan_num[1], window[0], window[1], fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definition: Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reusable scaling function\n",
    "def scale_data (data, scale_factor):\n",
    "    scaled_data = [d*scale_factor for d in data]\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: Scale X values\n",
    "- Example: scale datapoints to seconds: \n",
    "    - `unscaled = x_values` \n",
    "    - `scale_factor = 1/30000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unscaled = x_values \n",
    "x_scale_factor = 1/fs\n",
    "\n",
    "# Call the scale_data function\n",
    "x_scaled = scale_data (x_unscaled, x_scale_factor)\n",
    "display(HTML(\"\"\"Scaled X-axis data saved to the <strong>x_scaled</strong> \n",
    "             variable as <strong> datapoints </strong>.\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: Scale Y Values\n",
    "- Example: Scale raw y values to microvolts: \n",
    "   - `unscaled = y_values`\n",
    "   - `scale_factor = 0.195`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unscaled = y_values \n",
    "y_scale_factor = 0.195\n",
    "\n",
    "# Call the scale_data function\n",
    "y_scaled = []\n",
    "print(\"Scaling Channel:\", end = ' ')\n",
    "for i,y in enumerate(y_unscaled.T):  # Cycles through the transposed columns (channels) of y-axis data\n",
    "    print(i, end = ' ')\n",
    "    y_scaled.append (scale_data (y, y_scale_factor)) # Add the column to the new list of scaled data\n",
    "y_scaled = np.array(y_scaled).T  # make the list of scaled data a numpy array for speed/convenience\n",
    "display(HTML(\"Scaled y-axis data saved to the <strong>y_scaled</strong> variable.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass Filter the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definition: Butterworth Bandpass Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n",
    "        return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
    "        sos = butter_bandpass(lowcut, highcut, fs, order)\n",
    "        y = sosfiltfilt(sos, data)\n",
    "        return y\n",
    "\n",
    "def get_filtered (ys, lowcut, highcut, order, fs, df):\n",
    "    display (HTML(\"<h4>Analyzing channel: \"))\n",
    "    for chan in np.arange(ys.shape[1]):\n",
    "        print(chan, end = ' ')\n",
    "        order = 6\n",
    "        x = np.arange(len(ys[:,chan]))\n",
    "        sos = butter_bandpass(lowcut, highcut, fs, order)\n",
    "        w, h = sosfreqz(sos, worN=2000)\n",
    "        filtered[chan] = butter_bandpass_filter(ys[:,chan], lowcut, highcut, fs, order=order)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: Filtering (scaled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unfiltered = y_scaled # or y_values if you didn't need the scaling step\n",
    "fs = 30000              # Sample Rate, if using downsampled data remember to change this to 1000\n",
    "lowcut = 450            # Hz for bandpass filter\n",
    "highcut = 5000          # Hz for bandpass filter\n",
    "order = 6               # For bandpass filter \n",
    "\n",
    "filtered = pd.DataFrame()\n",
    "filtered = get_filtered(y_unfiltered, lowcut, highcut, order, fs, filtered)\n",
    "y_filtered = np.array(filtered)\n",
    "display(HTML(\"Filtered y-axis data saved to the <strong>y_filtered</strong> variable.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the downsampling() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(xs,ys,fs, new_fs):\n",
    "    by = fs/new_fs\n",
    "    x_downsampled = [xd/fs for xd in np.arange(0,max(xs), by)]\n",
    "    y_downsampled = []\n",
    "    for i,y in enumerate(ys):\n",
    "        y_downsampled.append(y)\n",
    "        i = i + 30\n",
    "    y_downsampled = np.array(y_downsampled)\n",
    "    return x_downsampled, y_downsampled                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User input: Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fs = x_values     \n",
    "y_fs = y_filtered   # or y_values or y_scaled, etc..\n",
    "fs = 30000          # current sample rat\n",
    "new_fs = 1000       # the desired sample rate\n",
    "\n",
    "# Call the downsampling() function\n",
    "x_downsampled, y_downsampled = downsampling(x_fs,y_fs,fs,new_fs)\n",
    "x_downsampled = np.array(x_downsampled)\n",
    "y_downsampled = np.array(y_downsampled)\n",
    "display(HTML(\"\"\"Downsampled x-axis data saved to the \n",
    "            <strong>x_downsampled</strong> variable as <strong>seconds</strong>\"\"\"))\n",
    "display(HTML(\"Downsampled y-axis data saved to the <strong>y_downsampled</strong> variable.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowpass Filter the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definition: Lowpass filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data, cutoff, fs, order,nyq):\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_lowpass (ys, highcut, order, fs):\n",
    "    filtered = []\n",
    "    display (HTML(\"<h4>Analyzing channel: \"))\n",
    "    for chan in np.arange(ys.shape[1]):\n",
    "        print(chan, end = ' ')\n",
    "        x = np.arange(len(ys[:,chan])) # sample x_values\n",
    "        n = len(x)  # number of samples\n",
    "        t = len(x)/fs # sample period (seconds)\n",
    "        signal_frequency = 15 # in Hz, highest desired frequency + buffer \n",
    "        nyq = fs/2\n",
    "        filtered.append(butter_lowpass_filter(ys[:,chan], highcut, fs, order, nyq))\n",
    "    filtered = np.array(filtered)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: Filtering (downsampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lowpass = y_downsampled  # or y_values if you didn't need the scaling step\n",
    "fs = 1000                     # Sample Rate, if using downsampled data remember to change this to 1000\n",
    "highcut = 15                  # Hz for bandpass filter\n",
    "order = 2                     # For sine wave, polynomial of 2 is appropriate \n",
    "\n",
    "ds_filtered = pd.DataFrame()\n",
    "ds_filtered = get_lowpass(y_lowpass, highcut, order, fs)\n",
    "y_downsampled_filtered = np.array(ds_filtered)\n",
    "display(HTML(\"\"\"Downsampled and filtered y-axis data \n",
    "            saved to the <strong>y_downsampled_filtered</strong> variable.\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Line Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define line_plot() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot (x,y,x_label, y_label, start, end):\n",
    "    start = int(start * fs)\n",
    "    end = int(end * fs)\n",
    "    fig, ax = plt.subplots(figsize = (20,5))\n",
    "    ax.plot(x[start:end],y[start:end])\n",
    "    ax.set_xlabel (x_label, fontsize = 16)\n",
    "    ax.set_ylabel (y_label, fontsize = 16)\n",
    "    ax.tick_params(labelsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: Plot Line Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = x_downsampled # or x_values if you didn't scale \n",
    "y_line = y_downsampled # or y_scale or y_values as you prefer\n",
    "channel = 0  \n",
    "start_plot = 0 # in seconds\n",
    "end_plot = 10   # in seconds\n",
    "x_label = 'Time (s)' # units of your x data\n",
    "y_label = 'Microvolts'\n",
    "\n",
    "# Call the line_plot function\n",
    "line_plot(x_line, y_line[:,channel],x_label, y_label, start_plot, end_plot )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data as Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definition: grid_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_plot(y_grid,columns, start, end, fs):\n",
    "    columns = np.array(columns)\n",
    "    start = int(start*30000)\n",
    "    end = int(end*30000)\n",
    "    xs = list(np.arange(len(y_grid[start:end,0])))\n",
    "    x = [x/fs for x in xs]\n",
    "    display(HTML('<hr><h4>Plotting channel: '))\n",
    "    fig, ax = plt.subplots (len(columns[0]),int(columns.shape[0]), figsize =(15,40), sharex = True, sharey = True)\n",
    "    j = 0\n",
    "    for j in np.arange (0,columns.shape[0]):\n",
    "        for i,col in enumerate(columns[j]): \n",
    "            if j == 1: # Offset for middle row (grid is 66 panels, but we only have 64 channels. Middle row is shorter) \n",
    "                i = i + 1\n",
    "            print(col, end = ' ')\n",
    "            ax[i][j].plot(x, y_grid[start:end,col], color = 'dimgray', \n",
    "                            label=str(col)) # Unfiltered Signal\n",
    "            handles, labels = ax[i][j].get_legend_handles_labels()\n",
    "            ax[i][j].legend(handles, labels, loc = 'upper right', fontsize = 8, shadow = False)\n",
    "            y_lims = ax[i][j].get_ylim()\n",
    "            ax[i][j].tick_params (labelsize = 12)\n",
    "    plt.tight_layout()\n",
    "    fig.text(0.0, 0.5, r'Amplitude ($\\mu$V)' + '\\n', ha='center', rotation='vertical', fontsize = 18)\n",
    "    fig.text(0.5, 0.0, '\\n Time (s)', va='center',  fontsize = 18)\n",
    "    plt.savefig (datafile.replace('.h5','_unfiltered' + str(chan_num[1]) + '.png'))\n",
    "    display(HTML('<hr>'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: Grid plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_grid = y_downsampled_filtered  # can be y_values, y_scaled, y_filtered, etc... as needed\n",
    "start_grid = 0 # in seconds\n",
    "end_grid = 5   # in seconds\n",
    "fs = 1000     # change if not downsampled\n",
    "# columns is a list of list representing the arrangement of channels on the shank\n",
    "# Within the column list are 3 sublists, each corresponding to a column on the shank\n",
    "# Top row is column 1, bottom is column 3\n",
    "# Channels to the left of the list are closer to the tip of the shank\n",
    "columns = [[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21], \n",
    "            [22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41], \n",
    "            [42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63]]  \n",
    "\n",
    "# call the grid_plot() function\n",
    "grid_plot(y_grid,columns, start_grid, end_grid, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Traces to a Nex CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nex_traces (ys, fs, save_name):\n",
    "    xs = list(np.arange(len(ys[:,0])))\n",
    "    x = [x/fs for x in xs]\n",
    "    df = pd.DataFrame()\n",
    "    df['time_seconds'] = x \n",
    "    for col in np.arange(ys.shape[1]):\n",
    "        df['Ch'+str(col)] =  ys[:,col]\n",
    "    df.to_csv(save_name, index = False)\n",
    "    print(display(HTML(df.head().to_html())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = y_filtered\n",
    "fs = 30000\n",
    "save_name = datafile.replace('.h5','_traces_nex.csv') # Can change this if needed\n",
    "nex_traces (ys,fs, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate CSVs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_concatenate(csv_files, common_column,save_file): \n",
    "    col_count = 0\n",
    "    out = pd.DataFrame()\n",
    "    for i,csv_file in enumerate(csv_files,0):\n",
    "        df = pd.read_csv(csv_files[i])\n",
    "        colnames = [int(col.split('Ch')[1])+(col_count) for \n",
    "                    col in df.columns[df.columns != common_column]]\n",
    "        for col in colnames:\n",
    "            out['Ch'+str(col)] = df['Ch'+ str(col-col_count)] \n",
    "        col_count = col_count + len(df.columns[df.columns != common_column]) \n",
    "    if common_column in df.columns.values:\n",
    "        out[common_column]=df[common_column]\n",
    "        out.to_csv(save_file)\n",
    "    out.to_csv(save_file, index = False)\n",
    "    return csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = ['experiment_C20200330-174152_filtered_192_events_nex.csv', 'experiment_C20200330-174152_filtered_192_events_nex.csv'] # list the filenames inside the brackets, separated by commas\n",
    "common_column = 'time_seconds' # (ie time_seconds) otherwise leave as empy quotation marks\n",
    "save_file = 'concatenated.csv'\n",
    "\n",
    "# Call the function\n",
    "csv_data = csv_concatenate(csv_files, common_column, save_file)\n",
    "csv_data = np.array(csv_data) # convert to numpy array for speed/compatibility\n",
    "\n",
    "# Check the conversion\n",
    "df = pd.read_csv(save_file)\n",
    "display(HTML(df.head().to_html()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H5 Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function: h5_concatenate_columns() and h5_concatenate_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5_concatenate_columns(datafiles, chan_range, save_name):\n",
    "    df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i,f in enumerate(datafiles):\n",
    "        channels = list(np.arange(chan_range[0],chan_range[1]))\n",
    "        f_data = h5py.File(f, 'r') # Read in the h5 file\n",
    "        ys = f_data.get('channel_data')  # actual data in raw format, must be scaled to microvolts (y)\n",
    "        xs = list(np.arange(len(ys[:,0])))\n",
    "        df_temp = pd.DataFrame(ys)\n",
    "        df_temp.columns = ['Ch' + str(chan + count) for chan in np.arange(len(df_temp.columns.values))]\n",
    "        df = df.join(df_temp)\n",
    "        count = count + len(df_temp.columns.values)\n",
    "        print(\"Columns after file \" + str(i) + \": \" + str(len(df.columns.values)))\n",
    "    hf = h5py.File(save_name.replace('.h5', '_cols.h5'), 'w')\n",
    "    hf.create_dataset('sample_index', data = list(np.arange(len(df.columns.values))))\n",
    "    hf.create_dataset('channel_data', data = df)\n",
    "    hf.close()\n",
    "    \n",
    "def h5_concatenate_rows(datafiles, chan_range, save_name):\n",
    "    df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i,f in enumerate(datafiles):\n",
    "        channels = list(np.arange(chan_range[0],chan_range[1]))\n",
    "        f_data = h5py.File(f, 'r') # Read in the h5 file\n",
    "        ys = f_data.get('channel_data')  # actual data in raw format, must be scaled to microvolts (y)\n",
    "        xs = list(np.arange(len(ys[:,0])))\n",
    "        df_temp = pd.DataFrame(ys)\n",
    "        df = df.append(df_temp)\n",
    "        print('Rows after file '+ str(i) +': ' + str(len(df.iloc[:][0])))\n",
    "        count = count + len(df_temp.columns.values)\n",
    "    hf = h5py.File(save_name.replace('.h5', '_rows.h5'), 'w')\n",
    "    hf.create_dataset('sample_index', data = list(np.arange(len(df.columns.values))))\n",
    "    hf.create_dataset('channel_data', data = df)\n",
    "    hf.close()\n",
    "    \n",
    "def h5_concatenate (datafiles, chan_range, save_name, rows_or_columns):\n",
    "    if rows_or_columns == 'rows':\n",
    "        h5_concatenate_rows (datafiles, chan_range, save_name)\n",
    "    elif rows_or_columns == 'columns':\n",
    "        h5_concatenate_columns(datafiles, chan_range, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: h5_concatenate\n",
    "- Be sure to list the files in order that you want them concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = ['experiment_C20200330-174152_chunk0.h5',\n",
    "            'experiment_C20200330-174152_chunk1.h5']\n",
    "chan_range = [0,64]\n",
    "save_name = 'experiment_C20200330-174152_concat.h5'\n",
    "rows_or_columns = 'columns'    # Choose whether to concatenate by rows or columns\n",
    "\n",
    "# Call the h5_concatenate function\n",
    "h5_concatenate(datafiles, chan_range, save_name, rows_or_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H5 Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definition: h5_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5_saver (save_name, x_values, y_values):\n",
    "    hf = h5py.File(save_name, 'w')\n",
    "    hf.create_dataset('sample_index', data = x_values)\n",
    "    hf.create_dataset('channel_data', data = y_values)\n",
    "    hf.close()\n",
    "\n",
    "def h5_splitter (datafile, chunk_length, chunk_num, chan_range, fs):\n",
    "    channels = list(np.arange(chan_range[0], chan_range[1])) # list of channels for the current shank\n",
    "    f_data = h5py.File(datafile, 'r') # Read in the h5 file\n",
    "    x_values = f_data.get('sample_index') # time in datapoints (x)\n",
    "    y_values = f_data.get('channel_data')  # actual data in raw format, must be scaled to microvolts (y)\n",
    "\n",
    "    # cycle through the data and parcel out chunks\n",
    "    chunk_length = int(chunk_length * fs)\n",
    "    time_start = 0\n",
    "    time_end = int(time_start + chunk_length)\n",
    "    for chunk in np.arange(chunk_num):\n",
    "        x_tmp = x_values[time_start:time_end] \n",
    "        y_tmp = y_values[time_start:time_end, channels]\n",
    "        h5_saver(datafile.replace('.h5','_chunk'+str(chunk)+'.h5'), x_tmp, y_tmp)\n",
    "        time_start = time_start + chunk_length\n",
    "        time_end = time_end + chunk_length\n",
    "    f_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: h5_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'experiment_C20200330-174152.h5'\n",
    "chunk_length = 0.2 # Length of chunks in seconds\n",
    "chunk_num = 10\n",
    "chan_range = [0,64] # start and end of channel range (last one not included)\n",
    "fs = 30000\n",
    "\n",
    "h5_splitter (datafile, chunk_length, chunk_num, chan_range, fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "willow",
   "language": "python",
   "name": "willow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
